"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([["3549"],{72393:function(e,n,r){r.r(n),r.d(n,{frontMatter:()=>i,default:()=>d,toc:()=>c,metadata:()=>s,assets:()=>l,contentTitle:()=>a});var s=JSON.parse('{"id":"Observability/mimir-demo","title":"[Mimir \u5BE6\u6230] \u6253\u9020\u672C\u5730\u76E3\u63A7\u7CFB\u7D71","description":"Mimir \u5BE6\u6230\u6559\u5B78\uFF0C\u4F7F\u7528 Express.js \u6253\u9020\u5B8C\u6574\u7684\u76E3\u63A7\u7CFB\u7D71","source":"@site/docs/Observability/mimir-demo.mdx","sourceDirName":"Observability","slug":"/Observability/mimir-demo","permalink":"/RulerChen-Website/docs/Observability/mimir-demo","draft":false,"unlisted":false,"editUrl":"https://github.com/RulerChen/RulerChen-Website/tree/main/docs/Observability/mimir-demo.mdx","tags":[],"version":"current","lastUpdatedAt":1741098246000,"sidebarPosition":42,"frontMatter":{"title":"[Mimir \u5BE6\u6230] \u6253\u9020\u672C\u5730\u76E3\u63A7\u7CFB\u7D71","sidebar_position":42,"description":"Mimir \u5BE6\u6230\u6559\u5B78\uFF0C\u4F7F\u7528 Express.js \u6253\u9020\u5B8C\u6574\u7684\u76E3\u63A7\u7CFB\u7D71","keywords":["grafana","express","metrics","observability","mimir"]},"sidebar":"tutorialSidebar","previous":{"title":"[Mimir] \u667A\u6167\u4E4B\u6CC9 - Mimir \u555F\u8FEA\u76E3\u63A7\u65B0\u5883\u754C","permalink":"/RulerChen-Website/docs/Observability/mimir"},"next":{"title":"[Alloy] \u795E\u79D8\u935B\u9020 - Alloy \u935B\u5C31\u6578\u64DA\u65B0\u795E\u8A71","permalink":"/RulerChen-Website/docs/Observability/alloy"}}'),t=r(85893),o=r(50065);let i={title:"[Mimir \u5BE6\u6230] \u6253\u9020\u672C\u5730\u76E3\u63A7\u7CFB\u7D71",sidebar_position:42,description:"Mimir \u5BE6\u6230\u6559\u5B78\uFF0C\u4F7F\u7528 Express.js \u6253\u9020\u5B8C\u6574\u7684\u76E3\u63A7\u7CFB\u7D71",keywords:["grafana","express","metrics","observability","mimir"]},a=void 0,l={},c=[{value:"API Setup",id:"api-setup",level:2},{value:"Docker Compose",id:"docker-compose",level:2},{value:"Alloy",id:"alloy",level:3},{value:"Mimir",id:"mimir",level:3},{value:"Grafana",id:"grafana",level:3},{value:"PostgreSQL",id:"postgresql",level:3},{value:"Server",id:"server",level:3},{value:"Request",id:"request",level:3}];function m(e){let n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/RulerChen/grafana-demo/tree/main/express-mimir-local",children:"Github Repo Link"})}),"\n",(0,t.jsx)(n.p,{children:"\u9019\u7BC7\u6587\u7AE0\u4E2D\u7684\u76EE\u6A19\u662F\u5728\u672C\u5730\u7AEF\u4F7F\u7528 docker-compose \u6253\u9020\u76E3\u63A7\u7CFB\u7D71\uFF0C\u4F7F\u7528\u7684 tech-stack \u5305\u542B :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Node.js (Express.js) : \u7528\u65BC\u5EFA\u7ACB api server"}),"\n",(0,t.jsx)(n.li,{children:"PostgreSQL : \u7528\u65BC\u5132\u5B58\u8CC7\u6599"}),"\n",(0,t.jsx)(n.li,{children:"Postgres Exporter : \u7528\u65BC\u8F38\u51FA PostgreSQL \u7684 metrics"}),"\n",(0,t.jsx)(n.li,{children:"Alloy : \u7528\u65BC\u5C07\u4E0D\u540C\u7684\u6307\u6A19\u8F49\u9001\u5230 mimir \u4E2D\u5132\u5B58"}),"\n",(0,t.jsx)(n.li,{children:"Mimir : \u7528\u65BC\u5132\u5B58 metrics"}),"\n",(0,t.jsx)(n.li,{children:"Grafana : \u7528\u65BC\u8996\u89BA\u5316\u5100\u8868\u677F"}),"\n",(0,t.jsx)(n.li,{children:"Curl : \u7528\u65BC\u6A21\u64EC request"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Demo \u7684\u6A94\u6848\u7D50\u69CB\u5982\u4E0B :"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",children:"\u251C\u2500 config\n\u2502  \u251C\u2500 alloy\n\u2502  \u2502  \u2514\u2500 config.alloy\n\u2502  \u251C\u2500 grafana\n\u2502  \u2502  \u251C\u2500 dashboards\n\u2502  \u2502  \u2502  \u251C\u2500 nodejs.json\n\u2502  \u2502  \u2502  \u2514\u2500 postgres.json\n\u2502  \u2502  \u2514\u2500 provisioning\n\u2502  \u2502     \u251C\u2500 dashboards\n\u2502  \u2502     \u2502  \u2514\u2500 dashboard.yaml\n\u2502  \u2502     \u2514\u2500 datasources\n\u2502  \u2502        \u2514\u2500 datasources.yaml\n\u2502  \u251C\u2500 mimir\n\u2502  \u2502  \u2514\u2500 mimir.yaml\n\u2502  \u2514\u2500 postgres\n\u2502     \u2514\u2500 init.sql\n\u251C\u2500 docker-compose.yaml\n\u251C\u2500 Dockerfile\n\u251C\u2500 docs\n\u2502  \u251C\u2500 image-1.png\n\u2502  \u2514\u2500 image.png\n\u251C\u2500 index.mjs\n\u251C\u2500 package-lock.json\n\u251C\u2500 package.json\n\u2514\u2500 README.md\n"})}),"\n",(0,t.jsx)(n.h2,{id:"api-setup",children:"API Setup"}),"\n",(0,t.jsx)(n.p,{children:"\u9996\u5148\u9700\u8981\u5EFA\u7ACB\u4E00\u4E9B\u7C21\u55AE\u7684 api\uFF0C\u9019\u88E1\u6211\u4F7F\u7528 Express.js \u9019\u500B\u6846\u67B6\uFF0C\u4E26\u7528 prom-client \u4F86\u8A18\u9304\u6307\u6A19\u3002"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"npm i express prom-client pg\n"})}),"\n",(0,t.jsxs)(n.p,{children:["\u63A5\u8457\u5728 ",(0,t.jsx)(n.code,{children:"index.js"})," \u4E2D\u5EFA\u7ACB\u4E00\u4E9B\u7C21\u55AE\u7684 api\uFF0C\u4E26\u52A0\u4E0A\u4E00\u500B middleware \u4F86\u8A18\u9304\u6307\u6A19\uFF0C\u7E3D\u5171\u6709\u56DB\u7A2E\u4E0D\u540C\u7684\u6307\u6A19\uFF0C\u50B3\u9001\u7684 request \u6578\u91CF\u3001request \u7684\u6642\u9593\u3001request \u7684\u5927\u5C0F\u3001response \u7684\u5927\u5C0F\u3002"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",metastring:'title="index.mjs"',children:"import express from 'express';\nimport promClient from 'prom-client';\nimport pg from 'pg';\n\nconst app = express();\napp.use(express.json());\n\nconst pool = new pg.Pool({\n  host: 'postgres',\n  port: 5432,\n  user: 'postgres',\n  password: 'postgres',\n  database: 'postgres'\n});\n\nconst register = new promClient.Registry();\nregister.setContentType(promClient.Registry.OPENMETRICS_CONTENT_TYPE);\n\npromClient.collectDefaultMetrics({ register });\n\nconst httpRequestCounter = new promClient.Counter({\n  name: 'http_requests_total',\n  help: 'Total number of HTTP requests',\n  labelNames: ['method', 'route', 'status']\n});\nregister.registerMetric(httpRequestCounter);\n\nconst httpRequestDurationHistogram = new promClient.Histogram({\n  name: 'http_request_duration_seconds',\n  help: 'Duration of HTTP requests in seconds',\n  labelNames: ['method', 'route', 'status'],\n  buckets: [0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 10]\n});\nregister.registerMetric(httpRequestDurationHistogram);\n\nconst httpRequestLengthHistogram = new promClient.Histogram({\n  name: 'http_request_length_bytes',\n  help: 'Length of HTTP requests in bytes',\n  labelNames: ['method', 'route'],\n  buckets: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n});\nregister.registerMetric(httpRequestLengthHistogram);\n\nconst httpResponseLengthHistogram = new promClient.Histogram({\n  name: 'http_response_length_bytes',\n  help: 'Length of HTTP responses in bytes',\n  labelNames: ['method', 'route'],\n  buckets: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n});\nregister.registerMetric(httpResponseLengthHistogram);\n\napp.use((req, res, next) => {\n  const start = Date.now();\n\n  res.on('finish', () => {\n    httpRequestCounter.labels(req.method, req.route.path, res.statusCode).inc();\n    httpRequestDurationHistogram\n      .labels(req.method, req.route.path, res.statusCode)\n      .observe(Date.now() - start);\n    httpRequestLengthHistogram.labels(req.method, req.route.path).observe(req.socket.bytesRead);\n    httpResponseLengthHistogram.labels(req.method, req.route.path).observe(req.socket.bytesWritten);\n  });\n  next();\n});\n\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', register.contentType);\n  res.end(await register.metrics());\n});\n\napp.get('/api/book/:bookId', async (req, res) => {\n  try {\n    const result = await pool.query('SELECT id, title FROM books WHERE id = $1', [\n      req.params.bookId\n    ]);\n    if (result.rowCount === 0) {\n      return res.status(404).send('Book not found');\n    }\n    res.status(200).send(result.rows[0]);\n  } catch (error) {\n    console.error(error);\n    res.status(500).send('Internal server error');\n  }\n});\n\napp.post('/api/book', async (req, res) => {\n  try {\n    const { title } = req.body;\n    if (!title) {\n      return res.status(400).send('Title is required');\n    }\n    await pool.query('INSERT INTO books (title) VALUES ($1)', [title]);\n    res.status(201).send();\n  } catch (error) {\n    console.error(error);\n    res.status(500).send('Internal server error');\n  }\n});\n\napp.delete('/api/book/:bookId', async (req, res) => {\n  try {\n    await pool.query('DELETE FROM books WHERE id = $1', [req.params.bookId]);\n    res.status(204).send();\n  } catch (error) {\n    console.error(error);\n    res.status(500).send('Internal server error');\n  }\n});\n\napp.listen(8000, async () => {\n  try {\n    await pool.connect();\n    await pool.query(`\n    CREATE TABLE IF NOT EXISTS books (\n        id SERIAL PRIMARY KEY,\n        title TEXT NOT NULL\n        )\n    `);\n  } catch (error) {\n    console.error(error);\n    process.exit(1);\n  }\n  console.log('Server is running on http://localhost:8000');\n});\n"})}),"\n",(0,t.jsx)(n.p,{children:"\u4E26\u4F7F\u7528\u7C21\u55AE\u7684 Dockerfile \u4F86\u6253\u5305\u6211\u5011\u7684 server\u3002"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-dockerfile",metastring:'title="Dockerfile"',children:'FROM node:20-alpine3.18\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --production\nCOPY . .\n\nEXPOSE 8000\n\nCMD ["node", "index.mjs"]\n'})}),"\n",(0,t.jsx)(n.h2,{id:"docker-compose",children:"Docker Compose"}),"\n",(0,t.jsx)(n.p,{children:"\u63A5\u4E0B\u4F86\u8A2D\u5B9A docker-compose \u4EE5\u53CA\u5404\u500B\u670D\u52D9\u7684 config file :"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"docker compose up -d\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:'title="docker-compose.yaml"',children:"name: mimir-demo\n\nservices:\n  alloy:\n    container_name: alloy\n    image: grafana/alloy:v1.7.1\n    restart: always\n    command: ['run', '--server.http.listen-addr=0.0.0.0:12345', '/etc/alloy/config.alloy']\n    healthcheck:\n      test:\n        [\n          'CMD',\n          '/bin/bash',\n          '-c',\n          \"echo -e 'GET /-/ready HTTP/1.1\\\\nHost: localhost\\\\nConnection: close\\\\n\\\\n' > /dev/tcp/localhost/12345\"\n        ]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n      start_period: 5s\n    volumes:\n      - ./config/alloy/config.alloy:/etc/alloy/config.alloy\n    ports:\n      - '12345:12345'\n    depends_on:\n      postgres:\n        condition: service_healthy\n        restart: true\n\n  mimir:\n    container_name: mimir\n    image: grafana/mimir:2.15.0\n    restart: always\n    command: ['-ingester.native-histograms-ingestion-enabled=true', '-config.file=/etc/mimir.yaml']\n    ports:\n      - '9009:9009'\n    volumes:\n      - './config/mimir/mimir.yaml:/etc/mimir.yaml'\n\n  grafana:\n    container_name: grafana\n    image: grafana/grafana:11.5.1\n    restart: always\n    environment:\n      - GF_AUTH_ANONYMOUS_ENABLED=true\n      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin\n      - GF_AUTH_DISABLE_LOGIN_FORM=true\n    healthcheck:\n      test: ['CMD', 'curl', '-f', 'http://localhost:3000/api/health']\n      interval: 5s\n      timeout: 5s\n      retries: 5\n      start_period: 5s\n    volumes:\n      - ./config/grafana/provisioning:/etc/grafana/provisioning\n      - ./config/grafana/dashboards:/var/lib/grafana/dashboards\n    ports:\n      - '3000:3000'\n\n  postgres:\n    container_name: postgres\n    image: postgres:16.8\n    restart: always\n    command:\n      [\n        'postgres',\n        '-c',\n        'shared_preload_libraries=pg_stat_statements',\n        '-c',\n        'pg_stat_statements.track=all'\n      ]\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n      POSTGRES_DB: postgres\n    healthcheck:\n      test: ['CMD', 'pg_isready', '-U', 'postgres']\n      interval: 5s\n      timeout: 5s\n      retries: 10\n      start_period: 5s\n    volumes:\n      - ./config/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql\n    ports:\n      - '5432:5432'\n\n  postgres-exporter:\n    container_name: postgres-exporter\n    image: prometheuscommunity/postgres-exporter:v0.17.1\n    restart: always\n    environment:\n      DATA_SOURCE_NAME: 'postgresql://postgres:postgres@postgres:5432/postgres?sslmode=disable'\n    healthcheck:\n      test: ['CMD', 'pg_isready', '-U', 'postgres']\n      interval: 5s\n      timeout: 5s\n      retries: 10\n      start_period: 5s\n    ports:\n      - '9187:9187'\n\n  server:\n    container_name: server\n    build:\n      dockerfile: Dockerfile\n    restart: always\n    ports:\n      - '8000:8000'\n    depends_on:\n      alloy:\n        condition: service_healthy\n        restart: true\n      postgres:\n        condition: service_healthy\n        restart: true\n\n  request:\n    container_name: request\n    image: curlimages/curl:8.12.1\n    restart: always\n    command: |\n      sh -c 'while true; do\n        method=$$(echo \"GET POST PUT DELETE\" | tr \" \" \"\\n\" | shuf -n1)\n        bookId=$$(shuf -i 1-100 -n1)\n        case $$method in\n          GET)\n            ep=$$(echo \"/api/book/$$bookId\" | tr \" \" \"\\n\" | shuf -n1)\n            curl -s -X GET http://server:8000$$ep\n            ;;\n          POST)\n            curl -s -X POST -H \"Content-Type: application/json\" http://server:8000/api/book -d \"{\\\"title\\\": \\\"Book $$bookId\\\"}\"\n            ;;\n          DELETE)\n            curl -s -X DELETE http://server:8000/api/book/$$bookId\n            ;;\n        esac\n        sleep 0.05\n      done'\n"})}),"\n",(0,t.jsx)(n.h3,{id:"alloy",children:"Alloy"}),"\n",(0,t.jsxs)(n.p,{children:["\u53EF\u4EE5\u5728 ",(0,t.jsx)(n.code,{children:"localhost:12345"})," \u4E2D\u67E5\u770B alloy \u7684\u6D41\u7A0B\u5716 :"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"alloy",src:r(38157).Z+"",width:"1403",height:"850"})}),"\n",(0,t.jsxs)(n.p,{children:["config file \u7684\u8A2D\u5B9A\u5305\u542B\u4E86 infra (\u4F8B\u5982 grafana\u3001mimir\u3001alloy \u672C\u8EAB) \u7684 metrics (",(0,t.jsx)(n.code,{children:'prometheus.scrape "infra"'}),")\u3001\napp \u7684 metrics (",(0,t.jsx)(n.code,{children:"prometheus.scrape"}),") \u4EE5\u53CA\u672C\u6A5F (",(0,t.jsx)(n.code,{children:"prometheus.exporter.unix "}),") \u548C postgres \u7684 metrics (",(0,t.jsx)(n.code,{children:'prometheus.scrape "postgres"'}),")\u3002"]}),"\n",(0,t.jsxs)(n.p,{children:["\u9700\u8981\u6CE8\u610F\u7684\u662F\uFF0C\u6211\u539F\u672C\u6253\u7B97\u4F7F\u7528 ",(0,t.jsx)(n.code,{children:"prometheus.exporter.postgres"})," \u4F86\u8F38\u51FA postgres \u7684 metrics\uFF0C\u4F46\u662F\u5B83\u4F3C\u4E4E\u7121\u6CD5\u8490\u96C6\u5230\u8DDF cpu \u4EE5\u53CA memory \u76F8\u95DC\u7684\u8CC7\u6599\uFF0C\u56E0\u6B64\u5F8C\u4F86\u6539\u6210\u642D\u914D postgres-exporter \u4F86\u8F38\u51FA\uFF0C\u5982\u679C\u6709\u9700\u8981\u53EF\u4EE5\u53C3\u8003\u8A3B\u89E3\u4E2D\u7684\u8A2D\u5B9A\u3002"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",metastring:'title="config/alloy/config.alloy"',children:'prometheus.scrape "infra" {\n    targets = [\n        {"__address__" = "mimir:9009", service = "mimir"},\n        {"__address__" = "grafana:3000", service = "grafana"},\n        {"__address__" = "localhost:12345", service = "alloy"},\n    ]\n\n    scrape_interval = "15s"\n\n    forward_to = [prometheus.remote_write.mimir.receiver]\n\n    job_name = "infra"\n}\n\nprometheus.scrape "server" {\n    targets = [\n        {"__address__" = "server:8000", service = "server"},\n    ]\n\n    scrape_interval = "2s"\n    scrape_timeout = "2s"\n\n    forward_to = [prometheus.remote_write.mimir.receiver]\n\n    job_name = "server"\n}\n\nprometheus.exporter.unix "default" {\n}\n\n// This component scrapes the Unix exporter metrics generated above.\nprometheus.scrape "unix" {\n    targets = prometheus.exporter.unix.default.targets\n\n    forward_to = [prometheus.remote_write.mimir.receiver]\n\n    job_name = "node_exporter"\n}\n\n// // This component scrapes the Postgres exporter metrics.\n// prometheus.exporter.postgres "default" {\n//     data_source_names = ["postgres://postgres:postgres@postgres:5432/postgres?sslmode=disable"]\n//     enabled_collectors = [\n//         "database",\n//         "database_wraparound",\n//         "locks",\n//         "long_running_transactions",\n//         "postmaster",\n//         "process_idle",\n//         "replication",\n//         "replication_slot",\n//         "stat_activity_autovacuum",\n//         "stat_bgwriter",\n//         "stat_database",\n//         "stat_statements",\n//         "stat_user_tables",\n//         "stat_wal_receiver",\n//         "statio_user_indexes",\n//         "statio_user_tables",\n//         "wal",\n//     ]\n// }\n\n// prometheus.scrape "postgres" {\n//     targets = prometheus.exporter.postgres.default.targets\n\n//     forward_to = [prometheus.remote_write.mimir.receiver]\n\n//     job_name = "postgres"\n// }\n\nprometheus.scrape "postgres" {\n    targets = [\n        {"__address__" = "postgres-exporter:9187", service = "postgres"},\n    ]\n\n    forward_to = [prometheus.remote_write.mimir.receiver]\n\n    job_name = "postgres"\n}\n\n\nprometheus.remote_write "mimir" {\n    endpoint {\n        url = "http://mimir:9009/api/v1/push"\n\n        basic_auth {\n            username = ""\n            password = ""\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"mimir",children:"Mimir"}),"\n",(0,t.jsx)(n.p,{children:"Mimir \u7684\u8A2D\u5B9A\u57FA\u672C\u4E0A\u4E5F\u662F\u672C\u5730\u7684\u8A2D\u5B9A\uFF0C\u4E26\u4E14\u4F7F\u7528 local filesystem \u4F86\u5132\u5B58\u8CC7\u6599\uFF0C\u5BE6\u969B\u4E0A\u5728 production \u4E2D\u61C9\u8A72\u8981\u4F7F\u7528\u5176\u4ED6\u7684\u5132\u5B58\u65B9\u5F0F\u3002"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:'title="config/mimir/mimir.yaml"',children:"# For more information on this configuration, see the complete reference guide at\n# https://grafana.com/docs/mimir/latest/references/configuration-parameters/\n\n# Disable multi-tenancy and restrict to single tenant.\nmultitenancy_enabled: false\n\n# The block storage configuration determines where the metrics TSDB data is stored.\nblocks_storage:\n  # Use the local filesystem for block storage.\n  # Note: It is highly recommended not to use local filesystem for production data.\n  backend: filesystem\n  # Directory in which to store synchronised TSDB index headers.\n  bucket_store:\n    sync_dir: /tmp/mimir/tsdb-sync\n  # Directory in which to store configuration for object storage.\n  filesystem:\n    dir: /tmp/mimir/data/tsdb\n  # Direction in which to store TSDB WAL data.\n  tsdb:\n    dir: /tmp/mimir/tsdb\n\n# The compactor block configures the compactor responsible for compacting TSDB blocks.\ncompactor:\n  # Directory to temporarily store blocks underdoing compaction.\n  data_dir: /tmp/mimir/compactor\n  # The sharding ring type used to share the hashed ring for the compactor.\n  sharding_ring:\n    # Use memberlist backend store (the default).\n    kvstore:\n      store: memberlist\n\n# The distributor receives incoming metrics data for the system.\ndistributor:\n  # The ring to share hash ring data across instances.\n  ring:\n    # The address advertised in the ring. Localhost.\n    instance_addr: 127.0.0.1\n    # Use memberlist backend store (the default).\n    kvstore:\n      store: memberlist\n\n# The ingester receives data from the distributor and processes it into indices and blocks.\ningester:\n  # The ring to share hash ring data across instances.\n  ring:\n    # The address advertised in the ring. Localhost.\n    instance_addr: 127.0.0.1\n    # Use memberlist backend store (the default).\n    kvstore:\n      store: memberlist\n    # Only run one instance of the ingesters.\n    # Note: It is highly recommended to run more than one ingester in production, the default is an RF of 3.\n    replication_factor: 1\n\n# The ruler storage block configures ruler storage settings.\nruler_storage:\n  # Use the local filesystem for block storage.\n  # Note: It is highly recommended not to use local filesystem for production data.\n  backend: filesystem\n  filesystem:\n    # The directory in which to store rules.\n    dir: /tmp/mimir/rules\n\n# The server block configures the Mimir server.\nserver:\n  # Listen on port 9009 for all incoming requests.\n  http_listen_port: 9009\n  # Log messages at info level.\n  log_level: info\n\n# The store gateway block configures gateway storage.\nstore_gateway:\n  # Configuration for the hash ring.\n  sharding_ring:\n    # Only run a single instance. In production setups, the replication factor must\n    # be set on the querier and ruler as well.\n    replication_factor: 1\n\n# Global limits configuration.\nlimits:\n  # A maximum of 100000 exemplars in memory at any one time.\n  # This setting enables exemplar processing and storage.\n  max_global_exemplars_per_user: 100000\n  ingestion_rate: 30000\n"})}),"\n",(0,t.jsx)(n.h3,{id:"grafana",children:"Grafana"}),"\n",(0,t.jsx)(n.p,{children:"\u53EF\u4EE5\u5728 docker-compose \u4E2D\u8A2D\u5B9A\u597D provisioning\uFF0C\u4E26\u4E14\u5C07 dashboard \u8207 datasource \u7684\u8A2D\u5B9A\u6A94\u653E\u5728\u5C0D\u61C9\u7684\u8CC7\u6599\u593E\u4E2D :"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:'title="config/grafana/provisioning/datasources/datasources.yaml"',children:"apiVersion: 1\n\ndatasources:\n  - name: Mimir\n    type: prometheus\n    access: proxy\n    uid: mimir\n    url: http://mimir:9009/prometheus\n"})}),"\n",(0,t.jsx)(n.p,{children:"dashboard \u5247\u53EF\u4EE5\u76F4\u63A5\u53C3\u8003\u4E0A\u9762\u7684 GitHub Repo \u4E2D\u7684 json \u6A94\u6848\uFF0C\u6211\u4F7F\u7528\u7684\u662F\u4EE5\u4E0B\u5169\u500B template :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://grafana.com/grafana/dashboards/14565-node-js-dashboard/",children:"Node.js Dashboard"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://grafana.com/grafana/dashboards/9628-postgresql-database/",children:"PostgreSQL Dashboard"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"dashboards",src:r(27748).Z+"",width:"1890",height:"911"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"dashboards",src:r(20141).Z+"",width:"1886",height:"915"})}),"\n",(0,t.jsx)(n.h3,{id:"postgresql",children:"PostgreSQL"}),"\n",(0,t.jsxs)(n.p,{children:["\u5728 postgres \u4E2D\u6211\u5011\u9700\u8981\u555F\u7528 ",(0,t.jsx)(n.code,{children:"pg_stat_statements"})," \u9019\u500B extension \u4F86\u8A18\u9304 query \u7684 performance\uFF0C\u9700\u8981\u4FEE\u6539 config \u4E26\u4F7F\u7528 init.sql \u4F86\u521D\u59CB\u5316\u3002"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",metastring:'title="config/postgres/init.sql"',children:"CREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n"})}),"\n",(0,t.jsx)(n.h3,{id:"server",children:"Server"}),"\n",(0,t.jsxs)(n.p,{children:["\u525B\u525B\u5EFA\u7ACB\u7684 api server\uFF0C\u6703\u958B\u555F\u4E00\u500B ",(0,t.jsx)(n.code,{children:"/metrics"})," \u7684 endpoint \u4F86\u8F38\u51FA metrics\uFF0C\u53EF\u4EE5\u5728 ",(0,t.jsx)(n.code,{children:"localhost:8000/metrics"})," \u4E2D\u67E5\u770B\u3002"]}),"\n",(0,t.jsx)(n.h3,{id:"request",children:"Request"}),"\n",(0,t.jsx)(n.p,{children:"\u4F7F\u7528 curl \u6307\u4EE4\u96A8\u6A5F\u5C0D server \u7684\u5176\u4E2D\u4E00\u500B api \u767C\u9001 request\u3002"})]})}function d(e={}){let{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},38157:function(e,n,r){r.d(n,{Z:()=>s});let s=r.p+"assets/images/image-2-576b96c36c5553ae5ff071e71df627e7.png"},27748:function(e,n,r){r.d(n,{Z:()=>s});let s=r.p+"assets/images/image-3-8d468902afedb096ec1399b74f2be2d8.png"},20141:function(e,n,r){r.d(n,{Z:()=>s});let s=r.p+"assets/images/image-4-ed42d3365208c2bfb11f5a51de09c29b.png"},50065:function(e,n,r){r.d(n,{Z:()=>a,a:()=>i});var s=r(67294);let t={},o=s.createContext(t);function i(e){let n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);